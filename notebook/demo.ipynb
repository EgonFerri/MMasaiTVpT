{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "import gradio as gr\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sn\n",
    "\n",
    "from tensorflow.keras.layers import Input,Dense,Bidirectional,Conv2D,MaxPooling2D,Flatten,concatenate,GlobalAveragePooling2D,BatchNormalization,Lambda,Add,Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel, TFBertModel, logging\n",
    "\n",
    "from utilities import *\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_block(inputs):\n",
    "    X = tf.keras.layers.BatchNormalization()(inputs)\n",
    "    X = tf.keras.layers.Dense(512, activation='relu')(X)\n",
    "    X = tf.keras.layers.Dropout(0.2)(X)\n",
    "    X = tf.keras.layers.Dense(128, activation='relu')(X)\n",
    "    X = tf.keras.layers.Dropout(0.2)(X)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(X)  # 3 labels due to three sentiment classes\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=50\n",
    "seq_len2=10\n",
    "\n",
    "model=  \"unideeplearning/polibert_sa\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "bert = TFBertModel.from_pretrained(model)\n",
    "\n",
    "CNN = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224,224,3), pooling=False, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "input_ids2 = tf.keras.layers.Input(shape=(seq_len2,), name='input_ids2', dtype='int32')\n",
    "mask2 = tf.keras.layers.Input(shape=(seq_len2,), name='attention_mask2', dtype='int32')\n",
    "\n",
    "input_ids_c=tf.keras.layers.concatenate([input_ids, input_ids2])\n",
    "mask_c=tf.keras.layers.concatenate([mask, mask2])\n",
    "\n",
    "image_inputs=tf.keras.layers.Input(shape=(224,224,3),name=\"images\")\n",
    "\n",
    "text_embeddings = bert(input_ids_c, attention_mask=mask_c)[0]  # we only keep tensor 0 (last_hidden_state)\n",
    "text_1d = tf.keras.layers.GlobalMaxPool1D()(text_embeddings)  # reduce tensor dimensionality\n",
    "\n",
    "image_embeddings=CNN(image_inputs)\n",
    "image_1d=GlobalAveragePooling2D()(image_embeddings)\n",
    "\n",
    "X=tf.keras.layers.concatenate([text_1d, image_1d])\n",
    "\n",
    "y=class_block(X)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, mask,input_ids2, mask2, image_inputs], outputs=y)\n",
    "\n",
    "# freeze the DistilBERT layer\n",
    "model.layers[7].trainable = False\n",
    "model.layers[8].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1573a51df70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('saves/final_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_finale(im):\n",
    "    im= cv2.bilateralFilter(im,5, 55,60)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    _, im = cv2.threshold(im, 240, 255, 1)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_config = r\"--oem 3 --psm 11 -c tessedit_char_whitelist='ABCDEFGHIJKLMNOPQRSTUVWXYZ '\"\n",
    "labels=['negative', 'neutral', 'positive']\n",
    "\n",
    "def ext_text(tweet_text, tweet_image):\n",
    "    text1=tweet_text\n",
    "    im= tweet_image\n",
    "    \n",
    "    img1 = preprocess_finale(im)\n",
    "    text = pytesseract.image_to_string(img1, lang='ita', config=custom_config)\n",
    "    text = text.replace('\\n', '')\n",
    "    \n",
    "    toktx=tokenize(text1, tokenizer, SEQ_LEN=50)\n",
    "    toktx2=tokenize(text, tokenizer, SEQ_LEN=10)\n",
    "    image = preprocess_image(im,labels=None, prediction=True)\n",
    "    prediction= model.predict([toktx,toktx2,image])\n",
    "    \n",
    "    return img1, text, {labels[i]: float(prediction[0][i]) for i in range(0,3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7860/\n",
      "This share link will expire in 24 hours. If you need a permanent link, email support@gradio.app\n",
      "Running on External URL: https://38010.gradio.app\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"https://38010.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1573a656640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>,\n",
       " 'http://127.0.0.1:7860/',\n",
       " 'https://38010.gradio.app')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iface = gr.Interface(fn=ext_text, inputs=[gr.inputs.Textbox(), gr.inputs.Image()], \n",
    "                     outputs=[gr.outputs.Image(label='Preprocessed image'),                               \n",
    "                              gr.outputs.Textbox(label='Extracted Text'), \n",
    "                              gr.outputs.Label(num_top_classes=3, label='Predicted sentiment')],\n",
    "                     examples=[('', 'examples/example'+str(i)+'.png') for i in range(1,6)]\n",
    "                    )\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
